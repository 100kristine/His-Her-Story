{
 "metadata": {
  "name": "",
  "signature": "sha256:e897dd81d45aeccefae78ea46c9535d1205963351e7bd6652db5b66e8fcaf618"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.util import bigrams,trigrams\n",
      "import pickle,nltk\n",
      "stop = set(stopwords.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pickle.load(open('tagged_tokenized_data_full_fromTheBride','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Wedding Graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def helper():\n",
      "    #Can't pickle lambdas, use helper\n",
      "    return defaultdict(int)\n",
      "\n",
      "class Graph:\n",
      "    \"\"\"Weighted undirected graph to model relationships between words. \n",
      "    Example:\n",
      "    >>> graph = Graph()\n",
      "    >>> graph.addObjs(objs)\n",
      "    >>> graph.getFreq('family',10) #get the top n words related to family\n",
      "    ['traditions',\n",
      "     'performed',\n",
      "     'mother',\n",
      "     'friend',\n",
      "     'ceremony',\n",
      "     'wrote',\n",
      "     'world',\n",
      "     'wonderful',\n",
      "     'well',\n",
      "     'walk']\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.graph = defaultdict(helper)\n",
      "\n",
      "    def addObjs(self,data):\n",
      "        #Adds word to graph\n",
      "        count = 0\n",
      "        for obj in data:\n",
      "            if count%50 == 0:\n",
      "                print count, \" objects added\"\n",
      "            #categories = reduce(lambda x,y: x+y, [obj['categories'][key] for key in obj['categories'].keys()])\n",
      "            #collapsed = categories + list(set(getTextItems(obj)))\n",
      "            #for item in collapsed:\n",
      "            #    for other in collapsed:\n",
      "            #        if other != item:\n",
      "            #            self.graph[item][other] += 1\n",
      "            pars = getTextItemsPar(obj)\n",
      "            for par in pars:\n",
      "                self.addParagraph(par)\n",
      "            count += 1\n",
      "    \n",
      "    def addParagraph(self,paragraph):\n",
      "        for word in paragraph:\n",
      "            for other in paragraph:\n",
      "                if word != other:\n",
      "                    self.graph[word][other] += 1\n",
      "                    \n",
      "    \n",
      "    def getFreq(self,word,n):\n",
      "        #Get top n frequencies of connected words\n",
      "        top = [(self.graph[word][key],key) for key in self.graph[word].keys()]\n",
      "        top.sort(reverse=True)\n",
      "        return [top[i] for i in range(n)]\n",
      "    \n",
      "    def connections(self,word):\n",
      "        return len(self.graph[word].keys())\n",
      "\n",
      "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "def getTextItemsCollapsed(sample):\n",
      "    return reduce(lambda x,y:x+y,[removeStopwords(item) for item in sample['tokens']])\n",
      "\n",
      "def getTextItemsPar(sample):\n",
      "    pars = []\n",
      "    for par in sample['paragraphs']:\n",
      "        pars.append(reduce(lambda x,y: x+y, [removeStopwords(nltk.word_tokenize(sent)) for sent in nltk.sent_tokenize(par)]))\n",
      "    return pars#reduce(lambda x,y:x+y,[removeStopwords(item) for item in sample['paragraphs']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Theme of wedding\n",
      "# Favorite Part\n",
      "# Wanted/Goals\n",
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#g = Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#g.addObjs([data[key] for key in data.keys()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#len(g.graph.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#g.getFreq(\"wedding\",10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(g,open('superGraph','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unigrams, Bigrams, and Trigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def removeStopwords(text):\n",
      "    return [word.lower() for word in text if len(word) > 2 and word.lower() not in stop]\n",
      "\n",
      "def cleanUnigrams(sample):\n",
      "    try:\n",
      "        return reduce(lambda x,y:x+y,[removeStopwords(sentence) for sentence in sample['tokens']])\n",
      "    except:\n",
      "        return []\n",
      "def cleanNgrams(sample,doBigrams=True):\n",
      "    \"\"\"\n",
      "    >>> cleanNgrams(obj,False) #trigrams\n",
      "    >>> cleanNgrams(obj,True)  #bigrams\n",
      "    \"\"\"\n",
      "    cleaned = []\n",
      "    for sentence in sample['tokens']:\n",
      "        if doBigrams:\n",
      "            temp = [bigram for bigram in bigrams(sentence) if len(set(bigram)&stop)==0]\n",
      "        else:\n",
      "            temp = [trigram for trigram in trigrams(sentence) if len(set(trigram)&stop)==0]\n",
      "        if len(temp) > 0:\n",
      "            cleaned += (temp)\n",
      "    return cleaned\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Global data processing\n",
      "Need to:\n",
      "\n",
      "count all n-grams in range [1,3]\n",
      "\n",
      "remove entries with malformed text (some destination weddings are not formatted the same way)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Clean data and remove destination weddings that didn't load properly\n",
      "\"\"\"\n",
      "for key in data.keys():\n",
      "    if len(data[key]['tokens']) == 0:\n",
      "        print key\n",
      "        del data[key]\n",
      "pickle.dump(data,open('tagged_tokenized_data_full_fromTheBride','w'))\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "\"\\nfor key in data.keys():\\n    if len(data[key]['tokens']) == 0:\\n        print key\\n        del data[key]\\npickle.dump(data,open('tagged_tokenized_data_full_fromTheBride','w'))\\n\""
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "dataBigrams,dataTrigrams,dataUnigrams = [],[],[]\n",
      "for key in data.keys():\n",
      "    dataBigrams += cleanNgrams(data[key],True)\n",
      "    dataTrigrams += cleanNgrams(data[key],False)\n",
      "    dataUnigrams += cleanUnigrams(data[key])\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'\\ndataBigrams,dataTrigrams,dataUnigrams = [],[],[]\\nfor key in data.keys():\\n    dataBigrams += cleanNgrams(data[key],True)\\n    dataTrigrams += cleanNgrams(data[key],False)\\n    dataUnigrams += cleanUnigrams(data[key])\\n'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(dataBigrams,open('allBigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(dataUnigrams,open('allUnigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(dataTrigrams,open('allTrigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#nltk.FreqDist(dataBigrams).most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"Leaving in contractions. \n",
      "In some cases, the 's is just possessive, but in others,\n",
      "it is a word - eg she's going = she is going\"\"\"\n",
      "#nltk.FreqDist(dataTrigrams).most_common(20) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "\"Leaving in contractions. \\nIn some cases, the 's is just possessive, but in others,\\nit is a word - eg she's going = she is going\""
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#nltk.FreqDist(dataUnigrams).most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}