{
 "metadata": {
  "name": "",
  "signature": "sha256:0ed3d08a93bbecd308b670c80ad54f737ca172059b34307ce3a3bf2df5c50209"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.util import bigrams,trigrams\n",
      "import pickle,nltk\n",
      "stop = set(stopwords.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('tagged_tokenized_data_full_fromTheBride','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Wedding Graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "class Graph:\n",
      "    \"\"\"Weighted undirected graph to model relationships between words. \n",
      "    Example:\n",
      "    >>> graph = Graph()\n",
      "    >>> graph.addObjs(objs)\n",
      "    >>> graph.getFreq('family',10) #get the top n words related to family\n",
      "    ['traditions',\n",
      "     'performed',\n",
      "     'mother',\n",
      "     'friend',\n",
      "     'ceremony',\n",
      "     'wrote',\n",
      "     'world',\n",
      "     'wonderful',\n",
      "     'well',\n",
      "     'walk']\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.graph = defaultdict(lambda:defaultdict(int))\n",
      "\n",
      "    def addObjs(self,data):\n",
      "        #Adds word to graph\n",
      "        count = 0\n",
      "        for obj in data:\n",
      "            if count%50 == 0:\n",
      "                print count, \" objects added\"\n",
      "            categories = reduce(lambda x,y: x+y, [obj['categories'][key] for key in obj['categories'].keys()])\n",
      "            collapsed = categories + list(set(getTextItems(obj)))\n",
      "            for item in collapsed:\n",
      "                for other in collapsed:\n",
      "                    if other != item:\n",
      "                        self.graph[item][other] += 1\n",
      "            count += 1\n",
      "    \n",
      "    def getFreq(self,word,n):\n",
      "        #Get top n frequencies of connected words\n",
      "        top = [(self.graph[word][key],key) for key in self.graph[word].keys()]\n",
      "        top.sort(reverse=True)\n",
      "        return [top[i] for i in range(n)]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g.addObjs([data[key] for key in data.keys()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  objects added\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "250"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "350"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "450"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "750"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "850"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  objects added\n",
        "900"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g.getFreq(\"love\",10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "[(29, 'wedding'),\n",
        " (29, 'day'),\n",
        " (27, 'one'),\n",
        " (24, 'bride'),\n",
        " (23, 'made'),\n",
        " (22, 'family'),\n",
        " (22, 'ceremony'),\n",
        " (21, 'pink'),\n",
        " (21, 'perfect'),\n",
        " (21, 'friends')]"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unigrams, Bigrams, and Trigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def removeStopwords(text):\n",
      "    return [word.lower() for word in text if len(word) > 2 and word.lower() not in stop]\n",
      "\n",
      "def cleanUnigrams(sample):\n",
      "    try:\n",
      "        return reduce(lambda x,y:x+y,[removeStopwords(sentence) for sentence in sample['tokens']])\n",
      "    except:\n",
      "        return []\n",
      "def cleanNgrams(sample,doBigrams=True):\n",
      "    \"\"\"\n",
      "    >>> cleanNgrams(obj,False) #trigrams\n",
      "    >>> cleanNgrams(obj,True)  #bigrams\n",
      "    \"\"\"\n",
      "    cleaned = []\n",
      "    for sentence in sample['tokens']:\n",
      "        if doBigrams:\n",
      "            temp = [bigram for bigram in bigrams(sentence) if len(set(bigram)&stop)==0]\n",
      "        else:\n",
      "            temp = [trigram for trigram in trigrams(sentence) if len(set(trigram)&stop)==0]\n",
      "        if len(temp) > 0:\n",
      "            cleaned += (temp)\n",
      "    return cleaned\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Global data processing\n",
      "Need to:\n",
      "\n",
      "count all n-grams in range [1,3]\n",
      "\n",
      "remove entries with malformed text (some destination weddings are not formatted the same way)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Clean data and remove destination weddings that didn't load properly\n",
      "for key in data.keys():\n",
      "    if len(data[key]['tokens']) == 0:\n",
      "        print key\n",
      "        del data[key]\n",
      "pickle.dump(data,open('tagged_tokenized_data_full_fromTheBride','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataBigrams,dataTrigrams,dataUnigrams = [],[],[]\n",
      "for key in data.keys():\n",
      "    dataBigrams += cleanNgrams(data[key],True)\n",
      "    dataTrigrams += cleanNgrams(data[key],False)\n",
      "    dataUnigrams += cleanUnigrams(data[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sample = data[data.keys()[0]]\n",
      "#removeStopwords(sample['tokens'][0])\n",
      "def getTextItems(sample):\n",
      "    return reduce(lambda x,y:x+y,[removeStopwords(item) for item in sample['tokens']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(dataBigrams,open('allBigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(dataUnigrams,open('allUnigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(dataTrigrams,open('allTrigrams','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.FreqDist(dataBigrams).most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "[(('wedding', 'day'), 383),\n",
        " (('wedding', 'dress'), 192),\n",
        " (('cocktail', 'hour'), 150),\n",
        " (('dance', 'floor'), 131),\n",
        " (('get', 'married'), 121),\n",
        " (('destination', 'wedding'), 115),\n",
        " (('full', 'gallery'), 114),\n",
        " (('wedding', 'planner'), 113),\n",
        " (('big', 'day'), 112),\n",
        " (('beautiful', 'bride'), 106),\n",
        " (('took', 'place'), 104),\n",
        " (('wedding', 'cake'), 97),\n",
        " (('special', 'day'), 96),\n",
        " (('bridal', 'party'), 96),\n",
        " (('first', 'dance'), 90),\n",
        " (('san', 'francisco'), 87),\n",
        " (('floral', 'design'), 86),\n",
        " (('feel', 'like'), 85),\n",
        " (('every', 'detail'), 84),\n",
        " (('first', 'look'), 82)]"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"Leaving in contractions. \n",
      "In some cases, the 's is just possessive, but in others,\n",
      "it is a word - eg she's going = she is going\"\"\"\n",
      "nltk.FreqDist(dataTrigrams).most_common(20) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[(('ceremony', 'took', 'place'), 41),\n",
        " (('bride', \"'s\", 'shoes'), 33),\n",
        " (('groom', \"'s\", 'attire'), 26),\n",
        " (('shoes', 'jimmy', 'choo'), 18),\n",
        " (('ann', 'kam', 'photography'), 17),\n",
        " (('groom', \"'s\", 'shoes'), 16),\n",
        " (('wedding', 'planning', 'process'), 14),\n",
        " (('kam', 'photography', 'cinema'), 14),\n",
        " (('new', 'york', 'city'), 14),\n",
        " (('michael', 'anna', 'costa'), 14),\n",
        " (('two', 'birds', 'photography'), 13),\n",
        " (('made', 'us', 'feel'), 13),\n",
        " (('photography', 'floral', 'design'), 13),\n",
        " (('wedding', 'took', 'place'), 13),\n",
        " (('ll', 'never', 'forget'), 12),\n",
        " (('chicago', 'history', 'museum'), 11),\n",
        " (('groom', \"'s\", 'suit'), 11),\n",
        " (('anna', 'costa', 'photography'), 11),\n",
        " (('see', 'every', 'last'), 11),\n",
        " (('served', 'family', 'style'), 10)]"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.FreqDist(dataUnigrams).most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[('wedding', 4948),\n",
        " ('day', 2370),\n",
        " ('love', 1576),\n",
        " ('one', 1531),\n",
        " ('beautiful', 1325),\n",
        " ('bride', 1268),\n",
        " ('wanted', 1259),\n",
        " ('guests', 1242),\n",
        " ('ceremony', 1147),\n",
        " ('made', 1080),\n",
        " ('family', 1074),\n",
        " ('perfect', 954),\n",
        " ('friends', 942),\n",
        " ('photography', 895),\n",
        " ('would', 849),\n",
        " ('together', 818),\n",
        " ('like', 788),\n",
        " ('time', 766),\n",
        " ('first', 754),\n",
        " ('every', 716)]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}