{
 "metadata": {
  "name": "",
  "signature": "sha256:bb67ea1ec465203d6d6c2b32131594e66065f8dddfa3bcbe9b42db6f1a4ea28c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import pickle\n",
      "from nltk.util import trigrams,bigrams\n",
      "import random\n",
      "from nltk.chunk import*\n",
      "from nltk.chunk.regexp import*\n",
      "from nltk.chunk.util import*\n",
      "from collections import defaultdict\n",
      "from nltk.corpus import brown\n",
      "import nltk.grammar\n",
      "from nltk.parse import generate\n",
      "from nltk import CFG"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run weddingGraph.ipynb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = [\"California_1-21\",\"California_22-81\",\"California_83-143\"]\n",
      "\n",
      "def loadData(files):\n",
      "    #data in format {url: textObject}\n",
      "    res = []\n",
      "    for f in files:\n",
      "        res += pickle.load(open(f,'r'))\n",
      "    d = defaultdict()\n",
      "    for result in res:\n",
      "        d[result['original_link']] = result\n",
      "    return d\n",
      "\n",
      "def tokenizeSentenceOnly(sentence):\n",
      "    return [word for word in nltk.word_tokenize(sentence) if word not in string.punctuation]\n",
      "\n",
      "def tokenize(pars):\n",
      "    #tokenize text\n",
      "    # returns cleaned [tokenized sentences without punctuation] and collapsed [no dividers between sentences]\n",
      "    strng = ' '.join(pars)\n",
      "    words = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(strng)]\n",
      "    punct = string.punctuation\n",
      "    cleaned = []\n",
      "    collapsed = []\n",
      "    for sentence in words:\n",
      "        cleaned.append([word for word in sentence if word not in punct])\n",
      "        for word in sentence:\n",
      "            if word not in punct:\n",
      "                collapsed.append(word)\n",
      "    return cleaned,collapsed\n",
      "\n",
      "def tag(sents):\n",
      "    #tag text\n",
      "    return [nltk.pos_tag(sent) for sent in sents]\n",
      "\n",
      "def tagAll(textObjects):\n",
      "    tagged = []\n",
      "    for obj in textObjects:\n",
      "        tagged.append([tag(text) for text in obj['paragraphs']])\n",
      "    return tagged\n",
      "\n",
      "def tagNtoken(data):\n",
      "    for url in data.keys():\n",
      "        cleaned,collapsed = tokenize(data[url]['paragraphs'])\n",
      "        data[url]['tokens'] = cleaned\n",
      "        data[url]['tagged'] = tag(data[url]['tokens'])\n",
      "        data[url]['collapsed'] = collapsed\n",
      "    return data\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = loadData(files)\n",
      "#data = tagNtoken(data)\n",
      "\n",
      "#f = open('tagged_tokenized_data','w')\n",
      "#pickle.dump(data,f)\n",
      "#f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 474
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('tagged_tokenized_data_full_fromTheBride','r'))\n",
      "graph = pickle.load(open('superGraph','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for item in data.keys():\n",
      "#    temp = [word.lower() for word in data[item][\"collapsed\"]]\n",
      "#    data[item][\"collapsed\"] = temp\n",
      "#    other = []\n",
      "#    for sentence in data[item][\"tokens\"]:\n",
      "#        other.append([word.lower() for word in sentence])\n",
      "#    data[item][\"tokens\"] = other"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Explore the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Modify"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fromtheBride(dataObj):\n",
      "    #Return indices to slice out text/tokens related to \"from the bride\"\n",
      "    #Phrase is not always at the start of the sentence, due to tokenizer\n",
      "    fromBride = [None,None]\n",
      "    tokens = dataObj['tokens']\n",
      "    for i in range(len(tokens)):\n",
      "        bi = bigrams(tokens[i])\n",
      "        if ('from','the') in bi:\n",
      "            start = bi.index(('from','the'))\n",
      "            if (start + 2) < len(tokens[i]):\n",
      "                if tokens[i][start+2] == 'bride':\n",
      "                    fromBride[0] = i\n",
      "                else:\n",
      "                    fromBride[1] = i if i > 0 else None\n",
      "    if fromBride[0]:\n",
      "        if not fromBride[1]:\n",
      "            fromBride[1] = len(tokens)-1\n",
      "        return tokens[fromBride[0]:fromBride[1]]\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "def modify_data(data,itemName,function):\n",
      "    #cache more information\n",
      "    for key in data.keys():\n",
      "        change = function(data[key])\n",
      "        if change != None:\n",
      "            data[key][itemName] = change\n",
      "        else:\n",
      "            data[key][itemName] = False\n",
      "    return data\n",
      "#pickle.dump(data,open('tagged_tokenized_data_lowercase','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Chunking Code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getChunk(pattern,sentence):\n",
      "    #Get all phrases matching pattern in a single sentence\n",
      "    parser = RegexpChunkParser([ChunkRule(pattern,\"chunk\")],'phrase')\n",
      "    parsed = parser.parse(sentence)\n",
      "    return [i for i in parsed.subtrees(filter=lambda x: x.label() == 'phrase')]\n",
      "\n",
      "def collapseTree(tree,noTags=True,joinAll=False):\n",
      "    #Input: parse tree\n",
      "    #Outputs collapsed tree, set to no tags or joined (as string) \n",
      "    if noTags:\n",
      "        results = [sublst[0] for sublst in [lst for lst in tree.leaves()]]\n",
      "    else:\n",
      "        results = tree.leaves()\n",
      "    if joinAll:\n",
      "        return ' '.join(results)\n",
      "    return results\n",
      "    \n",
      "def getItems(listTrees,noTags=True,joinAll=False):\n",
      "    #Retrieve words from parse tree. Can set to not include tags\n",
      "    results = []\n",
      "    #for item in listTrees:\n",
      "    #if len(item) > 0:\n",
      "    for tree in listTrees:\n",
      "        if len(tree) > 0:\n",
      "            if noTags:\n",
      "                results.append([sublst[0] for sublst in [lst for lst in tree[0].leaves()]])\n",
      "            else:\n",
      "                results.append(tree[0].leaves())\n",
      "    if joinAll:\n",
      "        return [' '.join(result) for result in results]\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Get Building Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wedding = set([\"wedding\",\"marriage\",\"ceremony\",\"married\",\"marry\"])\n",
      "\n",
      "def getRelevantSentences(sample,setItems,tagged=True):\n",
      "    relevant = []\n",
      "    for sentence in sample['tokens']:\n",
      "        intersection  = setItems & set(sentence)\n",
      "        if len(intersection) > 0:\n",
      "            if tagged:\n",
      "                relevant.append(sample['tagged'][sample['tokens'].index(sentence)])\n",
      "            else:\n",
      "                relevant.append((sample['tokens'].index(sentence)))\n",
      "    return relevant\n",
      "\"\"\"\n",
      "def intent(sample):\n",
      "    #Collect all sentences that indicate some kind of intention or wish behind an action\n",
      "    #This may not be present if \"from the bride\" section is not in that post\n",
      "    #print sample[\"fromtheBride\"] != False\n",
      "    #Returns list of indices to the sentences which signify intent\n",
      "    relevant = []\n",
      "    for sentence in sample['tokens']: #so is too generic\n",
      "        intersection  = cause & set(sentence)\n",
      "        if len(intersection) > 0:\n",
      "            if \"since\" in intersection:\n",
      "                if \"ever since\" in ' '.join(sentence):\n",
      "                    continue\n",
      "            relevant.append((sample['tokens'].index(sentence)))\n",
      "    return relevant\n",
      "\"\"\"\n",
      "def getObjectOfIntent(sample):\n",
      "    indices = intent(sample)\n",
      "    #sentences = [sample['tokens'][i] for i in indices]\n",
      "    pattern = \"<PRP><VBD><TO>?<.*>*\" #Look behinds don't work?\n",
      "    results = []\n",
      "    for index in indices:\n",
      "        print  ' '.join(sample['collapsed'])\n",
      "        results.append(getChunk(pattern,sample['tagged'][index]))\n",
      "        print sample['tagged'][index]\n",
      "    return results#getItems(results,True,True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 400
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getRandomDataPoints(data,n=5):\n",
      "    indices = [random.randint(0,len(data)) for i in range(n)]\n",
      "    keys = data.keys()\n",
      "    randData = []\n",
      "    for index in indices:\n",
      "        randData.append(data[keys[index]])\n",
      "    return randData\n",
      "\n",
      "def testFunctionRandom(data,function,prnt=False):\n",
      "    #Selects 5 or fewer random posts to test function on.\n",
      "    randData = getRandomDataPoints(data)\n",
      "    results = []\n",
      "    for point in randData:\n",
      "        if prnt:\n",
      "            print point['paragraphs']\n",
      "        results.append(function(point))\n",
      "    return results\n",
      "\n",
      "def testFunction(data,function):\n",
      "    #Tests on entire set\n",
      "    indices = [random.randint(0,len(data)) for i in range(5)]\n",
      "    keys = data.keys()\n",
      "    for index in indices:\n",
      "        print keys[index]\n",
      "        function(data[keys[index]])\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 641
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Theme"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Helpers\n",
      "\n",
      "\n",
      "def getWantedPortion(verbs,taggedSentence):\n",
      "    for i in range(len(taggedSentence)):\n",
      "        if taggedSentence[i][0] in cause:\n",
      "            return taggedSentence[i:]\n",
      "    return []\n",
      "\n",
      "\"\"\"phrase: {<PRP><VBD><TO><.*>*}\"\"\"\n",
      "def getPhrases(expression):\n",
      "    \"\"\"Finds expressions related to inspiration for wedding. Returns as string.\"\"\"\n",
      "    parsed = nltk.RegexpParser(\"\"\"phrase: {<PRP.+>*<JJ.*|NN.*|DT|CC>*<JJ.*>+<NN.*>+}\n",
      "                                          {<TO><VB><VBN><IN>}\n",
      "                                          {<JJ.*>+<CC>*<JJ.*>*<JJ.*|NN.*>}\n",
      "                                          {<DT>+<NN|JJ>+<DT|NN|IN|JJ|CC>+<NN.*>+<VBG>?}\n",
      "                                          {<JJ|NN>+<JJ|NN|CC>+<NN.*>+}\n",
      "                                          {<JJ|NN.*><NN.*|JJ><CC><JJ>*<NN.*>}\n",
      "                                          \"\"\").parse(expression)\n",
      "    \n",
      "    results = [i.leaves() for i in parsed.subtrees(filter=lambda x: x.label() == 'phrase')]\n",
      "    return [' '.join([r[0] for r in res]) for res in results]\n",
      "\n",
      "#print getWantedPortion(cause,ex1)\n",
      "\n",
      "def causeTests():\n",
      "    ex1 = nltk.pos_tag('we wanted our wedding to incorporate our favorite things so we peppered little touches in the details'.split(' '))\n",
      "    ex2 = nltk.pos_tag('ever since i was a little girl i always wanted to get married outside'.split(' '))\n",
      "\n",
      "    ex3 = nltk.pos_tag('I wanted the look to be elegant classic and timeless but also contemporary and fresh'.split(' '))\n",
      "    ex4 = nltk.pos_tag('I wanted the inside of the reception room to be a white wonderland with flowers galore and the furniture to be sleek white and contemporary with a lounge feel'.split(' '))\n",
      "    ex5 = nltk.pos_tag(\"tara wanted the evening to reflect her laid-back style\".split(\" \"))\n",
      "    ex6 = nltk.pos_tag(\"my goal was to have a wedding that reflected my personal style\".split(\" \"))\n",
      "\n",
      "    print getPhrases(getWantedPortion(cause,ex1))\n",
      "    print getPhrases(getWantedPortion(cause,ex2))\n",
      "    print getPhrases(getWantedPortion(cause,ex3))\n",
      "    print getPhrases(getWantedPortion(cause,ex4))\n",
      "    print getPhrases(getWantedPortion(cause,ex5))\n",
      "    print getPhrases(getWantedPortion(cause,ex6))\n",
      "    return\n",
      "\n",
      "def getWeddingInspiration(sample):\n",
      "    cause = set([\"desired\",\"desire\",\"goal\",\"sought\",\"planned\",\"decided\",\"wanted\",\"intended\",\"intent\",\"wished\",\"believed\",\"chose\"])\n",
      "    relevant = getRelevantSentences(sample,cause,tagged=True)\n",
      "    #print relevant\n",
      "    #if len(relevant) == 0:\n",
      "    #    print sample['paragraphs']\n",
      "    return [item[0] for item in [getPhrases(sentence) for sentence in relevant] if len(item) >0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 672
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "\n",
      "def extract(pattern,tokens):\n",
      "    trees = [tree.leaves() for tree in getChunk(pattern,tokens)]\n",
      "    return [' '.join([sub[0] for sub in tree]) for tree in trees]\n",
      "    \n",
      "def parseIntro(sample):\n",
      "    #Curator usually also characterizes wedding\n",
      "    tokens = nltk.pos_tag(tokenizeSentenceOnly(sample['paragraphs'][0]))\n",
      "    results = extract(\"<JJ>+<JJ|DT>*<NN|NNS>+\",tokens)\n",
      "    bad = set([\"gallery\",\"idea\",\"bride\",\"sense\",\"photo\",\"thing\",\"photoshoot\", \"t\",\"s\",\"good\"])\n",
      "    return filter(lambda x:len(set(x.split(' '))&bad)==0,results)\n",
      "\n",
      "\n",
      "def getKeyphrases(sample):\n",
      "    results = []\n",
      "    for sentence in sample[\"tagged\"]:\n",
      "        results += extract(\"<JJ>+<JJ>*<NN|NNS>+\",sentence)\n",
      "    bad = set(['s','t'])\n",
      "    return filter(lambda x:len(set(x.split(' '))&bad)==0,results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 673
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#testFunctionRandom(data,parseIntro)\n",
      "pts = getRandomDataPoints(data,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 674
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for pt in pts:\n",
      "    print \"Inspirations and Desires: \",getWeddingInspiration(pt)\n",
      "    print \"Blogger's Description: \", parseIntro(pt)\n",
      "    print \"Keyphrases: \", getKeyphrases(pt)\n",
      "    print \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Inspirations and Desires:  ['the integrity of the design but update the material', 'a less traditional wedding band']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['beach convos', 'watercolor-blue waters', 'tropical-loving moment']\n",
        "Keyphrases:  ['beach convos', 'watercolor-blue waters', 'tropical-loving moment', 'classic yet elegant design', 'fitted sheath dress', 'humid weather', 'detailed beading', 'ocean front', 'panoramic view', 'tropical cocktails', 'clear blue waters', 'anniversary trip', 'simple design', 'traditional wedding band', 'rose gold', 'pave setting', 'classic white flowers', 'local florist', 'rustic feel', 'floral designer', 'bridal party bouquets boutonnieres', 'simple centerpieces', 'sustainable stainless steel cups', 'many margaritas', 'small envelopes', 'late night snack', 'cheese empanadas', 'final song', 'open-air dance floor']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['the gorgeous Barcelo Bavaro Palace Deluxe Hotel Punta Cana', 'both live in Chicago', 'fresh coconut drinks']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['whole lot', 'beautiful pink hue', 'entire day']\n",
        "Keyphrases:  ['whole lot', 'beautiful pink hue', 'entire day', 'chic garden destination', 'tropical paradise', 'fresh coconut drinks', 'gorgeous intimate garden', 'sweet ceremony', 'open-air reception space', 'whimsical ombre cake']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['traditional classic and beautiful']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['major reason', 'light the emotion', 'elegant al fresco details', 'full day unfold']\n",
        "Keyphrases:  ['major reason', 'elegant al fresco details', 'full day unfold', 'beautiful weddings', 'few occasions', 'final dress', 'beautiful photography', 'obvious choice', 'only reception venue', 'beautiful mission gardens', 'many years', 'late night snack', 'historic olive trees', 'memorable day']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['different dresses', 'a handful of dresses', 'traditional boutonni res', 'our own vows']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['past the stunning', 'elegant whole', 'old world feel']\n",
        "Keyphrases:  ['elegant whole', 'old world feel', 'full gallery', 'beautiful garden', 'floral arrangements', 'different antique stores', 'organic seasonal arrangements', 'many places', 'different dresses', 'simple process', 'beautiful together', 'traditional boutonni res', 'unique pocket squares', 'few days', 'own vows', 'favorite part', 'good time', 'small wedding-']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['family and friends', 'a timeless look and feel', 'our first look']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['beautiful blooms']\n",
        "Keyphrases:  ['beautiful blooms', 'historic hotel', 'beautiful rehearsal party', 'live steel drum music cocktails', 'wonderful start', 'wonderful weekend', 'first look', 'beautiful ballroom', 'intricate woodwork', 'bridal party', 'Singer/songwriter musician', 'final ballroom', 'lounge/dance space', 'white dance floor', 'entire room', 'memorable weekend']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['something casual yet elegant']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['contemporary rooftop soiree', 'vibrant hues', 'last minute', 'love-filled moments']\n",
        "Keyphrases:  ['contemporary rooftop soiree', 'vibrant hues', 'last minute', 'love-filled moments', 'opposite teams', 'many weeks', 'first date', 'local restaurant', 'good dates', 'casual yet elegant', 'French doors', 'indoor/outdoor feel', 'old Italian styled arches', 'gorgeous floral arrangements', 'table arrangements']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['flower girl stole']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['romantic rain shower', 'lovely details', 'Parisian whimsy']\n",
        "Keyphrases:  ['romantic rain shower', 'lovely details', 'Parisian whimsy', 'east side', 'dear friends family', 'exact moment', 'clear umbrellas', 'gorgeous bride', 'gorgeous 7-year-old daughter', 'perfect rain drops', 'etsy-bought dress']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  ['cozy casual']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['next person', 'beautiful shoot']\n",
        "Keyphrases:  ['next person', 'beautiful shoot', 'gorgeous flowers', 'bold love', 'long shawl', 'beautiful white blanket', 'white t-shirt', 'past year', '10th anniversary', 'whole chapter', 'simple pillows', 'beautiful backdrop', 'perfect shawl', 'great job']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  []\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['drop-dead gorgeous English countryside', 'colorful blooms', 'stylish attire hello']\n",
        "Keyphrases:  ['drop-dead gorgeous English countryside', 'colorful blooms', 'stylish attire hello', 'English wedding venue', 'own church', 'garden party', 'beautiful English roses']\n",
        "\n",
        "\n",
        "Inspirations and Desires:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['personal and something', 'a bit of a clich', 'a soft romantic colour palette', 'the hardest things', 't want', 't pull', 'special suit', 'a big party']\n",
        "Blogger's Description:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['beautiful billowing tulle']\n",
        "Keyphrases:  ['beautiful billowing tulle', 'good starting point', 'first few weeks', 'few weeks', 'pear farms', 'idyllic scenery', 'traditional recce', 'simple modern-ish barn', 'gorgeous gardens', 'little boathouse', 'soft romantic colour palette', 'many ideas', 'brilliant wedding planner', 'few things', 'same location', 'own creative twist', 'national flower fynbos', 'frothy gown', 'several different style dresses', 'beautiful tulle', 'fluted sleeves', 'tiny sequins', 'emotional connection', 'whole day', 'simple pendant necklace', 'special suit', 'very warm climate', 'good tailors', 'forth photos phone calls emails', 'dark grey paisley', 'live band', 'no-one left', 'live music', 'classical duo', 'incredible jazz duo', 'song choices', 'big party', 'local restaurant', 'previous week']\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 675
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}