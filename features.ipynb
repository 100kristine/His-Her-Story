{
 "metadata": {
  "name": "",
  "signature": "sha256:cc3dbcb7bd8ab8b1ca23055a2232efec2511b66a144d8e52a0289aa78cac65be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "import nltk\n",
      "import pickle\n",
      "from nltk.util import trigrams,bigrams\n",
      "import random\n",
      "from nltk.chunk import*\n",
      "from nltk.chunk.regexp import*\n",
      "from nltk.chunk.util import*\n",
      "from collections import defaultdict\n",
      "from nltk.corpus import brown\n",
      "#from nltk.probability import LidstoneProbDist, WittenBellProbDist\n",
      "#estimator = lambda fdist, bins: LidstoneProbDist(fdist, 0.2)\n",
      "#lm = NgramModel(3, brown.words(categories='news'), estimator)\n",
      "\n",
      "#from nltk.CFG import *"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = [\"California_1-21\",\"California_22-81\",\"California_83-143\"]\n",
      "\n",
      "def loadData(files):\n",
      "    #data in format {url: textObject}\n",
      "    res = []\n",
      "    for f in files:\n",
      "        res += pickle.load(open(f,'r'))\n",
      "    d = defaultdict()\n",
      "    for result in res:\n",
      "        d[result['original_link']] = result\n",
      "    return d\n",
      "\n",
      "def tokenizeSentenceOnly(sentence):\n",
      "    return [word for word in nltk.word_tokenize(sentence) if word not in string.punctuation]\n",
      "\n",
      "def tokenize(pars):\n",
      "    #tokenize text\n",
      "    # returns cleaned [tokenized sentences without punctuation] and collapsed [no dividers between sentences]\n",
      "    strng = ' '.join(pars)\n",
      "    words = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(strng)]\n",
      "    punct = string.punctuation\n",
      "    cleaned = []\n",
      "    collapsed = []\n",
      "    for sentence in words:\n",
      "        cleaned.append([word for word in sentence if word not in punct])\n",
      "        for word in sentence:\n",
      "            if word not in punct:\n",
      "                collapsed.append(word)\n",
      "    return cleaned,collapsed\n",
      "\n",
      "def tag(sents):\n",
      "    #tag text\n",
      "    return [nltk.pos_tag(sent) for sent in sents]\n",
      "\n",
      "def tagAll(textObjects):\n",
      "    tagged = []\n",
      "    for obj in textObjects:\n",
      "        tagged.append([tag(text) for text in obj['paragraphs']])\n",
      "    return tagged\n",
      "\n",
      "def tagNtoken(data):\n",
      "    for url in data.keys():\n",
      "        cleaned,collapsed = tokenize(data[url]['paragraphs'])\n",
      "        data[url]['tokens'] = cleaned\n",
      "        data[url]['tagged'] = tag(data[url]['tokens'])\n",
      "        data[url]['collapsed'] = collapsed\n",
      "    return data\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 436
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = loadData(files)\n",
      "#data = tagNtoken(data)\n",
      "\n",
      "#f = open('tagged_tokenized_data','w')\n",
      "#pickle.dump(data,f)\n",
      "#f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 474
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('tagged_tokenized_data','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in data.keys():\n",
      "    temp = [word.lower() for word in data[item][\"collapsed\"]]\n",
      "    data[item][\"collapsed\"] = temp\n",
      "    other = []\n",
      "    for sentence in data[item][\"tokens\"]:\n",
      "        other.append([word.lower() for word in sentence])\n",
      "    data[item][\"tokens\"] = other\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Explore the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Modify"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fromtheBride(dataObj):\n",
      "    #Return indices to slice out text/tokens related to \"from the bride\"\n",
      "    #Phrase is not always at the start of the sentence, due to tokenizer\n",
      "    fromBride = [None,None]\n",
      "    tokens = dataObj['tokens']\n",
      "    for i in range(len(tokens)):\n",
      "        bi = bigrams(tokens[i])\n",
      "        if ('from','the') in bi:\n",
      "            start = bi.index(('from','the'))\n",
      "            if (start + 2) < len(tokens[i]):\n",
      "                if tokens[i][start+2] == 'bride':\n",
      "                    fromBride[0] = i\n",
      "                else:\n",
      "                    fromBride[1] = i if i > 0 else None\n",
      "    if fromBride[0]:\n",
      "        if not fromBride[1]:\n",
      "            fromBride[1] = len(tokens)-1\n",
      "        return tokens[fromBride[0]:fromBride[1]]\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "def modify_data(data,itemName,function):\n",
      "    #cache more information\n",
      "    for key in data.keys():\n",
      "        change = function(data[key])\n",
      "        if change != None:\n",
      "            data[key][itemName] = change\n",
      "        else:\n",
      "            data[key][itemName] = False\n",
      "    return data\n",
      "#pickle.dump(data,open('tagged_tokenized_data_lowercase','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Chunking Code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getChunk(pattern,sentence):\n",
      "    #Get all phrases matching pattern in a single sentence\n",
      "    parser = RegexpChunkParser([ChunkRule(pattern,\"chunk\")],'phrase')\n",
      "    parsed = parser.parse(sentence)\n",
      "    return [i for i in parsed.subtrees(filter=lambda x: x.node == 'phrase')]\n",
      "\n",
      "def collapseTree(tree,noTags=True,joinAll=False):\n",
      "    #Input: parse tree\n",
      "    #Outputs collapsed tree, set to no tags or joined (as string) \n",
      "    if noTags:\n",
      "        results = [sublst[0] for sublst in [lst for lst in tree.leaves()]]\n",
      "    else:\n",
      "        results = tree.leaves()\n",
      "    if joinAll:\n",
      "        return ' '.join(results)\n",
      "    return results\n",
      "    \n",
      "\n",
      "def getItems(listTrees,noTags=True,joinAll=False):\n",
      "    #Retrieve words from parse tree. Can set to not include tags\n",
      "    results = []\n",
      "    #for item in listTrees:\n",
      "    #if len(item) > 0:\n",
      "    for tree in listTrees:\n",
      "        if len(tree) > 0:\n",
      "            if noTags:\n",
      "                results.append([sublst[0] for sublst in [lst for lst in tree[0].leaves()]])\n",
      "            else:\n",
      "                results.append(tree[0].leaves())\n",
      "    if joinAll:\n",
      "        return [' '.join(result) for result in results]\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 461
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Get Building Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def intent(sample):\n",
      "    #Collect all sentences that indicate some kind of intention or wish behind an action\n",
      "    #This may not be present if \"from the bride\" section is not in that post\n",
      "    #print sample[\"fromtheBride\"] != False\n",
      "    #Returns list of indices to the sentences which signify intent\n",
      "    relevant = []\n",
      "    for sentence in sample['tokens']: #so is too generic\n",
      "        intersection  = cause & set(sentence)\n",
      "        if len(intersection) > 0:\n",
      "            if \"since\" in intersection:\n",
      "                if \"ever since\" in ' '.join(sentence):\n",
      "                    continue\n",
      "            relevant.append((sample['tokens'].index(sentence)))\n",
      "    return relevant\n",
      "\n",
      "def getObjectOfIntent(sample):\n",
      "    indices = intent(sample)\n",
      "    #sentences = [sample['tokens'][i] for i in indices]\n",
      "    pattern = \"<PRP><VBD><TO>?<.*>*\" #Look behinds don't work?\n",
      "    results = []\n",
      "    for index in indices:\n",
      "        results.append(getChunk(pattern,sample['tagged'][index]))\n",
      "        print sample['tagged'][index]\n",
      "    return getItems(results,True,True)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 403
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testFunctionRandom(data,function):\n",
      "    #Selects 5 or fewer random posts to test function on.\n",
      "    indices = [random.randint(0,len(data)) for i in range(5)]\n",
      "    keys = data.keys()\n",
      "    results = []\n",
      "    for index in indices:\n",
      "        print keys[index]\n",
      "        results.append(function(data[keys[index]]))\n",
      "    return results\n",
      "\n",
      "def testFunction(data,function):\n",
      "    #Tests on entire set\n",
      "    indices = [random.randint(0,len(data)) for i in range(5)]\n",
      "    keys = data.keys()\n",
      "    for index in indices:\n",
      "        print keys[index]\n",
      "        function(data[keys[index]])\n",
      "    return\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tag_pattern2re_pattern(\"<DT><NN>(<J.*|N.*|IN|CC|DT|TO>*)\")\n",
      "print test\n",
      "chunks = \"<DT><J.*><J.*|N.*|IN|CC|DT|TO>*<N*>\"\n",
      "[getChunk(chunks,sentence) for sentence in test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I wanted the look to be elegant classic and timeless but also contemporary and fresh\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "Tree() argument 2 should be a list, not a string",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-480-5a5724bf8cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<DT><J.*><J.*|N.*|IN|CC|DT|TO>*<N*>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mgetChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-461-dec01c63e255>\u001b[0m in \u001b[0;36mgetChunk\u001b[0;34m(pattern, sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Get all phrases matching pattern in a single sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpChunkParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChunkRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"chunk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'phrase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'phrase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Artemis/anaconda/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mchunk_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mchunk_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;31m# Use the default trace value?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Artemis/anaconda/lib/python2.7/site-packages/nltk/tree.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_or_str, children)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise TypeError(\"%s() argument 2 should be a list, not a \"\n\u001b[0;32m--> 104\u001b[0;31m                             \"string\" % type(self).__name__)\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: Tree() argument 2 should be a list, not a string"
       ]
      }
     ],
     "prompt_number": 480
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collap(,True,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = [[('We', 'PRP'),\n",
      "   ('knew', 'VBD'),\n",
      "   ('we', 'PRP'),\n",
      "   ('wanted', 'VBD'),\n",
      "   ('the', 'DT'),\n",
      "   ('vibe', 'NN'),\n",
      "   ('of', 'IN'),\n",
      "   ('the', 'DT'),\n",
      "   ('day', 'NN'),\n",
      "   ('to', 'TO'),\n",
      "   ('have', 'VB'),\n",
      "   ('touchs', 'NNS'),\n",
      "   ('of', 'IN'),\n",
      "   ('old', 'JJ'),\n",
      "   ('hollywood', 'NN'),\n",
      "   ('glam', 'NN'),\n",
      "   ('but', 'CC'),\n",
      "   ('with', 'IN'),\n",
      "   ('modern', 'JJ'),\n",
      "   ('elements', 'NNS'),\n",
      "   ('so', 'IN'),\n",
      "   ('as', 'IN'),\n",
      "   ('soon', 'RB'),\n",
      "   ('as', 'IN'),\n",
      "   ('I', 'PRP'),\n",
      "   ('visited', 'VBD'),\n",
      "   ('Bacara', 'NNP'),\n",
      "   ('in', 'IN'),\n",
      "   ('person', 'NN'),\n",
      "   ('I', 'PRP'),\n",
      "   ('knew', 'VBD'),\n",
      "   ('it', 'PRP'),\n",
      "   ('was', 'VBD'),\n",
      "   ('the', 'DT'),\n",
      "   ('perfect', 'NN'),\n",
      "   ('place', 'NN')]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = modify_data(data,\"fromtheBride\",fromtheBride)\n",
      "items\n",
      "#for i in items:\n",
      "#    if len(i) > 0:\n",
      "#        for tree in i:\n",
      "#            print tree[0].leaves()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 406,
       "text": [
        "[[],\n",
        " [],\n",
        " [],\n",
        " [],\n",
        " ['I wanted the look to be elegant classic and timeless but also contemporary and fresh',\n",
        "  'I wanted the inside of the reception room to be a white wonderland with flowers galore and the furniture to be sleek white and contemporary with a lounge feel',\n",
        "  'I wanted a simple sleek all white wedding cake accented by a few white flowers']]"
       ]
      }
     ],
     "prompt_number": 406
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "items = testFunctionRandom(data,getObjectOfIntent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.stylemepretty.com/2014/08/06/english-garden-inspired-wedding-in-southern-california/\n",
        "http://www.stylemepretty.com/california-weddings/los-angeles/downtown/2014/09/30/vintage-chic-wedding-in-downtown-los-angeles/\n",
        "http://www.stylemepretty.com/california-weddings/2014/08/05/seaside-california-wedding-at-the-gualala-arts-center/\n",
        "[('Set', 'NNP'), ('in', 'IN'), ('a', 'DT'), ('grove', 'NN'), ('a', 'DT'), ('redwoods', 'NNS'), ('the', 'DT'), ('Gualala', 'NNP'), ('Arts', 'NNP'), ('Center', 'NNP'), ('served', 'VBD'), ('the', 'DT'), ('perfect', 'NN'), ('backdrop', 'NN'), ('for', 'IN'), ('guests', 'NNS'), ('to', 'TO'), ('admire', 'VB'), ('the', 'DT'), ('beauty', 'NN'), ('of', 'IN'), ('this', 'DT'), ('special', 'JJ'), ('place', 'NN'), ('these', 'DT'), ('two', 'CD'), ('chose', 'JJ'), ('to', 'TO'), ('get', 'VB'), ('married', 'VBN')]\n",
        "http://www.stylemepretty.com/2014/11/03/romantic-forest-wedding-in-temecula/\n",
        "[('From', 'IN'), ('Sposto', 'NNP'), ('Photography', 'NNP'), ('Jenny', 'NNP'), ('and', 'CC'), ('Jeff', 'NNP'), ('chose', 'NN'), ('a', 'DT'), ('soft', 'JJ'), ('pastel', 'NN'), ('pallet', 'NN'), ('for', 'IN'), ('their', 'PRP$'), ('wedding', 'NN')]\n",
        "http://www.stylemepretty.com/2014/09/03/chic-so-cal-ballroom-wedding/\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('the', 'DT'), ('look', 'NN'), ('to', 'TO'), ('be', 'VB'), ('elegant', 'JJ'), ('classic', 'JJ'), ('and', 'CC'), ('timeless', 'NN'), ('but', 'CC'), ('also', 'RB'), ('contemporary', 'JJ'), ('and', 'CC'), ('fresh', 'JJ')]\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('the', 'DT'), ('inside', 'NN'), ('of', 'IN'), ('the', 'DT'), ('reception', 'NN'), ('room', 'NN'), ('to', 'TO'), ('be', 'VB'), ('a', 'DT'), ('white', 'JJ'), ('wonderland', 'NN'), ('with', 'IN'), ('flowers', 'NNS'), ('galore', 'VBP'), ('and', 'CC'), ('the', 'DT'), ('furniture', 'NN'), ('to', 'TO'), ('be', 'VB'), ('sleek', 'NN'), ('white', 'IN'), ('and', 'CC'), ('contemporary', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('lounge', 'NN'), ('feel', 'NN')]\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('a', 'DT'), ('simple', 'JJ'), ('sleek', 'NN'), ('all', 'DT'), ('white', 'NN'), ('wedding', 'VBG'), ('cake', 'NN'), ('accented', 'VBD'), ('by', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('white', 'JJ'), ('flowers', 'NNS')]\n"
       ]
      }
     ],
     "prompt_number": 405
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cause = set([\"desired\",\"desire\",\"goal\",\"wanted\",\"intended\",\"intent\",\"wished\",\"believed\",\"chose\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 324
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.randint(0,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = data[data.keys()[9]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseIntro(sample):\n",
      "    #Curator usually also characterizes wedding\n",
      "    nltk.pos_tag(tokenizeSentenceOnly(sample))\n",
      "    return tokenizeSentenceOnly(sample)\n",
      "tokens = nltk.pos_tag(tokenizeSentenceOnly(sample['paragraphs'][0]))\n",
      "np = getChunk(\"<JJ>+<NN|NNS>+\",tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 507
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[collapseTree(n,False,False) for n in np]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 510,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 510
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use relationship to tags\n",
      "sample['categories']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 509,
       "text": [
        "{'colors': ['blue', 'green', 'orange'],\n",
        " 'seasons': ['fall'],\n",
        " 'settings': ['al-fresco'],\n",
        " 'styles': ['classic']}"
       ]
      }
     ],
     "prompt_number": 509
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample['paragraphs']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 512,
       "text": [
        "['Fall = Romance, in my book. Something about warm colors aligned with the release from unrelenting heat beckons love. Take a look at this bride whose October wedding perfectly captures the feeling with rustic DIY touches, deep blue and orange hues (and succulents for a nice Southwestern touch). Keep scrolling for stunning images from the guys at Studio 7 who were there to document the event.',\n",
        " 'Seeing him made me immediately feel calm and at peace; this is what all of the planning was for! I did not hire a wedding planner, I wanted to be involved, and instead had a friend (who does weddings at another local venue) suggest some vendors for me and also manage the actual  Day Of  details. I tried throughout the process to keep it simple and let my vendors do what they do best by standing out of their way, but try as I might, there were still many details to sort out leading up to the  big day . However, from our  first look  on, I forgot about all those details. Everything fell into place and I felt stunned by the beauty of how everything came together. Also, because we kept the bridal party to just family, we had time to hang out and enjoy ourselves, keeping stress to a minimum.',\n",
        " 'The ceremony was the most special for me. Having my mother walk me down the aisle, to Louis Armstrong s  What a Wonderful World  brought tears to our eyes. A dear friend performed the ceremony that combined the traditions and values of our two cultures thoughtfully and respectfully. We included the Jewish traditions of the Chuppah and Ketubah, as well as stomping on a glass, and of course we danced the Hora at the reception. A friend of mine read a verse from the old testament and the new, representing the Christian faith of my family. Three of my mother s friends wrote a song for us, and performed it at dinner, which was a tradition in their family that was a hilarious addition to our night.',\n",
        " 'The evening was stayed warm enough for all to dance and mingle until it was over. And it was over so quickly! I m grateful to have these pictures that truly capture our joy.\\n']"
       ]
      }
     ],
     "prompt_number": 512
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = 'I wanted the look to be elegant classic and timeless but also contemporary and fresh'\n",
      "\n",
      "grammar = nltk.CFG.fromstring(\"\"\"\n",
      "S-> NP V NP\n",
      "NP -> NP\n",
      "V ->\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'CFG'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-418-8a4646f37ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I wanted the look to be elegant classic and timeless but also contemporary and fresh'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m grammar = nltk.CFG.fromstring(\"\"\"\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mNP\u001b[0m \u001b[0mV\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNP\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'CFG'"
       ]
      }
     ],
     "prompt_number": 418
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}