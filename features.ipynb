{
 "metadata": {
  "name": "",
  "signature": "sha256:beea1032e9e7f475ba3d861c2c8e04bf711af4d2904f241a9b2f9b5d14f5d39b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import pickle\n",
      "from nltk.util import trigrams,bigrams\n",
      "import random\n",
      "from nltk.chunk import*\n",
      "from nltk.chunk.regexp import*\n",
      "from nltk.chunk.util import*\n",
      "from collections import defaultdict\n",
      "from nltk.corpus import brown\n",
      "from nltk.probability import LidstoneProbDist, WittenBellProbDist\n",
      "estimator = lambda fdist, bins: LidstoneProbDist(fdist, 0.2)\n",
      "lm = NgramModel(3, brown.words(categories='news'), estimator)\n",
      "\n",
      "#from nltk.CFG import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'NgramModel' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-479-a4e58069706f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLidstoneProbDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWittenBellProbDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLidstoneProbDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgramModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#from nltk.CFG import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'NgramModel' is not defined"
       ]
      }
     ],
     "prompt_number": 479
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = [\"California_1-21\",\"California_22-81\",\"California_83-143\"]\n",
      "\n",
      "def loadData(files):\n",
      "    #data in format {url: textObject}\n",
      "    res = []\n",
      "    for f in files:\n",
      "        res += pickle.load(open(f,'r'))\n",
      "    d = defaultdict()\n",
      "    for result in res:\n",
      "        d[result['original_link']] = result\n",
      "    return d\n",
      "\n",
      "def tokenizeSentenceOnly(sentence):\n",
      "    return [word for word in nltk.word_tokenize(sentence) if word not in string.punctuation]\n",
      "\n",
      "def tokenize(pars):\n",
      "    #tokenize text\n",
      "    # returns cleaned [tokenized sentences without punctuation] and collapsed [no dividers between sentences]\n",
      "    strng = ' '.join(pars)\n",
      "    words = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(strng)]\n",
      "    punct = string.punctuation\n",
      "    cleaned = []\n",
      "    collapsed = []\n",
      "    for sentence in words:\n",
      "        cleaned.append([word for word in sentence if word not in punct])\n",
      "        for word in sentence:\n",
      "            if word not in punct:\n",
      "                collapsed.append(word)\n",
      "    return cleaned,collapsed\n",
      "\n",
      "def tag(sents):\n",
      "    #tag text\n",
      "    return [nltk.pos_tag(sent) for sent in sents]\n",
      "\n",
      "def tagAll(textObjects):\n",
      "    tagged = []\n",
      "    for obj in textObjects:\n",
      "        tagged.append([tag(text) for text in obj['paragraphs']])\n",
      "    return tagged\n",
      "\n",
      "def tagNtoken(data):\n",
      "    for url in data.keys():\n",
      "        cleaned,collapsed = tokenize(data[url]['paragraphs'])\n",
      "        data[url]['tokens'] = cleaned\n",
      "        data[url]['tagged'] = tag(data[url]['tokens'])\n",
      "        data[url]['collapsed'] = collapsed\n",
      "    return data\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 436
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = loadData(files)\n",
      "#data = tagNtoken(data)\n",
      "\n",
      "#f = open('tagged_tokenized_data','w')\n",
      "#pickle.dump(data,f)\n",
      "#f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 474
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('tagged_tokenized_data','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in data.keys():\n",
      "    temp = [word.lower() for word in data[item][\"collapsed\"]]\n",
      "    data[item][\"collapsed\"] = temp\n",
      "    other = []\n",
      "    for sentence in data[item][\"tokens\"]:\n",
      "        other.append([word.lower() for word in sentence])\n",
      "    data[item][\"tokens\"] = other\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Explore the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Modify"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fromtheBride(dataObj):\n",
      "    #Return indices to slice out text/tokens related to \"from the bride\"\n",
      "    #Phrase is not always at the start of the sentence, due to tokenizer\n",
      "    fromBride = [None,None]\n",
      "    tokens = dataObj['tokens']\n",
      "    for i in range(len(tokens)):\n",
      "        bi = bigrams(tokens[i])\n",
      "        if ('from','the') in bi:\n",
      "            start = bi.index(('from','the'))\n",
      "            if (start + 2) < len(tokens[i]):\n",
      "                if tokens[i][start+2] == 'bride':\n",
      "                    fromBride[0] = i\n",
      "                else:\n",
      "                    fromBride[1] = i if i > 0 else None\n",
      "    if fromBride[0]:\n",
      "        if not fromBride[1]:\n",
      "            fromBride[1] = len(tokens)-1\n",
      "        return tokens[fromBride[0]:fromBride[1]]\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "def modify_data(data,itemName,function):\n",
      "    #cache more information\n",
      "    for key in data.keys():\n",
      "        change = function(data[key])\n",
      "        if change != None:\n",
      "            data[key][itemName] = change\n",
      "        else:\n",
      "            data[key][itemName] = False\n",
      "    return data\n",
      "#pickle.dump(data,open('tagged_tokenized_data_lowercase','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Chunking Code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getChunk(pattern,sentence):\n",
      "    #Get all phrases matching pattern in a single sentence\n",
      "    parser = RegexpChunkParser([ChunkRule(pattern,\"chunk\")],'phrase')\n",
      "    parsed = parser.parse(sentence)\n",
      "    return [i for i in parsed.subtrees(filter=lambda x: x.node == 'phrase')]\n",
      "\n",
      "def collapseTree(tree,noTags=True,joinAll=False):\n",
      "    #Input: parse tree\n",
      "    #Outputs collapsed tree, set to no tags or joined (as string) \n",
      "    if noTags:\n",
      "        results = [sublst[0] for sublst in [lst for lst in tree.leaves()]]\n",
      "    else:\n",
      "        results = tree.leaves()\n",
      "    if joinAll:\n",
      "        return ' '.join(results)\n",
      "    return results\n",
      "    \n",
      "\n",
      "def getItems(listTrees,noTags=True,joinAll=False):\n",
      "    #Retrieve words from parse tree. Can set to not include tags\n",
      "    results = []\n",
      "    #for item in listTrees:\n",
      "    #if len(item) > 0:\n",
      "    for tree in listTrees:\n",
      "        if len(tree) > 0:\n",
      "            if noTags:\n",
      "                results.append([sublst[0] for sublst in [lst for lst in tree[0].leaves()]])\n",
      "            else:\n",
      "                results.append(tree[0].leaves())\n",
      "    if joinAll:\n",
      "        return [' '.join(result) for result in results]\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 461
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Get Building Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def intent(sample):\n",
      "    #Collect all sentences that indicate some kind of intention or wish behind an action\n",
      "    #This may not be present if \"from the bride\" section is not in that post\n",
      "    #print sample[\"fromtheBride\"] != False\n",
      "    #Returns list of indices to the sentences which signify intent\n",
      "    relevant = []\n",
      "    for sentence in sample['tokens']: #so is too generic\n",
      "        intersection  = cause & set(sentence)\n",
      "        if len(intersection) > 0:\n",
      "            if \"since\" in intersection:\n",
      "                if \"ever since\" in ' '.join(sentence):\n",
      "                    continue\n",
      "            relevant.append((sample['tokens'].index(sentence)))\n",
      "    return relevant\n",
      "\n",
      "def getObjectOfIntent(sample):\n",
      "    indices = intent(sample)\n",
      "    #sentences = [sample['tokens'][i] for i in indices]\n",
      "    pattern = \"<PRP><VBD><TO>?<.*>*\" #Look behinds don't work?\n",
      "    results = []\n",
      "    for index in indices:\n",
      "        results.append(getChunk(pattern,sample['tagged'][index]))\n",
      "        print sample['tagged'][index]\n",
      "    return getItems(results,True,True)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 403
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testFunctionRandom(data,function):\n",
      "    #Selects 5 or fewer random posts to test function on.\n",
      "    indices = [random.randint(0,len(data)) for i in range(5)]\n",
      "    keys = data.keys()\n",
      "    results = []\n",
      "    for index in indices:\n",
      "        print keys[index]\n",
      "        results.append(function(data[keys[index]]))\n",
      "    return results\n",
      "\n",
      "def testFunction(data,function):\n",
      "    #Tests on entire set\n",
      "    indices = [random.randint(0,len(data)) for i in range(5)]\n",
      "    keys = data.keys()\n",
      "    for index in indices:\n",
      "        print keys[index]\n",
      "        function(data[keys[index]])\n",
      "    return\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tag_pattern2re_pattern(\"<DT><NN>(<J.*|N.*|IN|CC|DT|TO>*)\")\n",
      "print test\n",
      "chunks = \"<DT><J.*><J.*|N.*|IN|CC|DT|TO>*<N*>\"\n",
      "[getChunk(chunks,sentence) for sentence in test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I wanted the look to be elegant classic and timeless but also contemporary and fresh\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "Tree() argument 2 should be a list, not a string",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-480-5a5724bf8cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<DT><J.*><J.*|N.*|IN|CC|DT|TO>*<N*>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mgetChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-461-dec01c63e255>\u001b[0m in \u001b[0;36mgetChunk\u001b[0;34m(pattern, sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Get all phrases matching pattern in a single sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpChunkParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChunkRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"chunk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'phrase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'phrase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Artemis/anaconda/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mchunk_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mchunk_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;31m# Use the default trace value?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Artemis/anaconda/lib/python2.7/site-packages/nltk/tree.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_or_str, children)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise TypeError(\"%s() argument 2 should be a list, not a \"\n\u001b[0;32m--> 104\u001b[0;31m                             \"string\" % type(self).__name__)\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: Tree() argument 2 should be a list, not a string"
       ]
      }
     ],
     "prompt_number": 480
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collap(,True,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = [[('We', 'PRP'),\n",
      "   ('knew', 'VBD'),\n",
      "   ('we', 'PRP'),\n",
      "   ('wanted', 'VBD'),\n",
      "   ('the', 'DT'),\n",
      "   ('vibe', 'NN'),\n",
      "   ('of', 'IN'),\n",
      "   ('the', 'DT'),\n",
      "   ('day', 'NN'),\n",
      "   ('to', 'TO'),\n",
      "   ('have', 'VB'),\n",
      "   ('touchs', 'NNS'),\n",
      "   ('of', 'IN'),\n",
      "   ('old', 'JJ'),\n",
      "   ('hollywood', 'NN'),\n",
      "   ('glam', 'NN'),\n",
      "   ('but', 'CC'),\n",
      "   ('with', 'IN'),\n",
      "   ('modern', 'JJ'),\n",
      "   ('elements', 'NNS'),\n",
      "   ('so', 'IN'),\n",
      "   ('as', 'IN'),\n",
      "   ('soon', 'RB'),\n",
      "   ('as', 'IN'),\n",
      "   ('I', 'PRP'),\n",
      "   ('visited', 'VBD'),\n",
      "   ('Bacara', 'NNP'),\n",
      "   ('in', 'IN'),\n",
      "   ('person', 'NN'),\n",
      "   ('I', 'PRP'),\n",
      "   ('knew', 'VBD'),\n",
      "   ('it', 'PRP'),\n",
      "   ('was', 'VBD'),\n",
      "   ('the', 'DT'),\n",
      "   ('perfect', 'NN'),\n",
      "   ('place', 'NN')]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = modify_data(data,\"fromtheBride\",fromtheBride)\n",
      "items\n",
      "#for i in items:\n",
      "#    if len(i) > 0:\n",
      "#        for tree in i:\n",
      "#            print tree[0].leaves()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 406,
       "text": [
        "[[],\n",
        " [],\n",
        " [],\n",
        " [],\n",
        " ['I wanted the look to be elegant classic and timeless but also contemporary and fresh',\n",
        "  'I wanted the inside of the reception room to be a white wonderland with flowers galore and the furniture to be sleek white and contemporary with a lounge feel',\n",
        "  'I wanted a simple sleek all white wedding cake accented by a few white flowers']]"
       ]
      }
     ],
     "prompt_number": 406
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "items = testFunctionRandom(data,getObjectOfIntent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.stylemepretty.com/2014/08/06/english-garden-inspired-wedding-in-southern-california/\n",
        "http://www.stylemepretty.com/california-weddings/los-angeles/downtown/2014/09/30/vintage-chic-wedding-in-downtown-los-angeles/\n",
        "http://www.stylemepretty.com/california-weddings/2014/08/05/seaside-california-wedding-at-the-gualala-arts-center/\n",
        "[('Set', 'NNP'), ('in', 'IN'), ('a', 'DT'), ('grove', 'NN'), ('a', 'DT'), ('redwoods', 'NNS'), ('the', 'DT'), ('Gualala', 'NNP'), ('Arts', 'NNP'), ('Center', 'NNP'), ('served', 'VBD'), ('the', 'DT'), ('perfect', 'NN'), ('backdrop', 'NN'), ('for', 'IN'), ('guests', 'NNS'), ('to', 'TO'), ('admire', 'VB'), ('the', 'DT'), ('beauty', 'NN'), ('of', 'IN'), ('this', 'DT'), ('special', 'JJ'), ('place', 'NN'), ('these', 'DT'), ('two', 'CD'), ('chose', 'JJ'), ('to', 'TO'), ('get', 'VB'), ('married', 'VBN')]\n",
        "http://www.stylemepretty.com/2014/11/03/romantic-forest-wedding-in-temecula/\n",
        "[('From', 'IN'), ('Sposto', 'NNP'), ('Photography', 'NNP'), ('Jenny', 'NNP'), ('and', 'CC'), ('Jeff', 'NNP'), ('chose', 'NN'), ('a', 'DT'), ('soft', 'JJ'), ('pastel', 'NN'), ('pallet', 'NN'), ('for', 'IN'), ('their', 'PRP$'), ('wedding', 'NN')]\n",
        "http://www.stylemepretty.com/2014/09/03/chic-so-cal-ballroom-wedding/\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('the', 'DT'), ('look', 'NN'), ('to', 'TO'), ('be', 'VB'), ('elegant', 'JJ'), ('classic', 'JJ'), ('and', 'CC'), ('timeless', 'NN'), ('but', 'CC'), ('also', 'RB'), ('contemporary', 'JJ'), ('and', 'CC'), ('fresh', 'JJ')]\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('the', 'DT'), ('inside', 'NN'), ('of', 'IN'), ('the', 'DT'), ('reception', 'NN'), ('room', 'NN'), ('to', 'TO'), ('be', 'VB'), ('a', 'DT'), ('white', 'JJ'), ('wonderland', 'NN'), ('with', 'IN'), ('flowers', 'NNS'), ('galore', 'VBP'), ('and', 'CC'), ('the', 'DT'), ('furniture', 'NN'), ('to', 'TO'), ('be', 'VB'), ('sleek', 'NN'), ('white', 'IN'), ('and', 'CC'), ('contemporary', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('lounge', 'NN'), ('feel', 'NN')]\n",
        "[('I', 'PRP'), ('wanted', 'VBD'), ('a', 'DT'), ('simple', 'JJ'), ('sleek', 'NN'), ('all', 'DT'), ('white', 'NN'), ('wedding', 'VBG'), ('cake', 'NN'), ('accented', 'VBD'), ('by', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('white', 'JJ'), ('flowers', 'NNS')]\n"
       ]
      }
     ],
     "prompt_number": 405
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cause = set([\"desired\",\"desire\",\"goal\",\"wanted\",\"intended\",\"intent\",\"wished\",\"believed\",\"chose\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 324
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.randint(0,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = data[data.keys()[8]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseIntro(sample):\n",
      "    #Curator usually also characterizes wedding\n",
      "    nltk.pos_tag(tokenizeSentenceOnly(sample))\n",
      "    return tokenizeSentenceOnly(sample)\n",
      "tokens = nltk.pos_tag(tokenizeSentenceOnly(sample['paragraphs'][0]))\n",
      "np = getChunk(\"<JJ>+<NN|NNS>+\",tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 499
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[collapseTree(n,False,False) for n in np]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 500,
       "text": [
        "[[('small', 'JJ'), ('elements', 'NNS')], [('modern', 'JJ'), ('beach', 'NN')]]"
       ]
      }
     ],
     "prompt_number": 500
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use relationship to tags\n",
      "sample['categories']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 505,
       "text": [
        "{'colors': ['lavender', 'light-pink', 'peach', 'purple'],\n",
        " 'seasons': ['spring'],\n",
        " 'settings': ['beach-resort'],\n",
        " 'styles': ['elegant']}"
       ]
      }
     ],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 478,
       "text": [
        "[('There', 'EX'),\n",
        " ('s', 'VBZ'),\n",
        " ('no', 'DT'),\n",
        " ('doubt', 'NN'),\n",
        " ('that', 'IN'),\n",
        " ('gorgeous', 'JJ'),\n",
        " ('imagery', 'NN'),\n",
        " ('is', 'VBZ'),\n",
        " ('our', 'PRP$'),\n",
        " ('fuel.', 'NNP'),\n",
        " ('It', 'NNP'),\n",
        " ('s', 'VBZ'),\n",
        " ('what', 'WP'),\n",
        " ('keeps', 'NNS'),\n",
        " ('us', 'PRP'),\n",
        " ('going', 'VBG'),\n",
        " ('every', 'DT'),\n",
        " ('day.', 'NNP'),\n",
        " ('But', 'CC'),\n",
        " ('the', 'DT'),\n",
        " ('stories', 'NNS'),\n",
        " ('The', 'DT'),\n",
        " ('stories', 'NNS'),\n",
        " ('are', 'VBP'),\n",
        " ('pure', 'JJ'),\n",
        " ('heart', 'NN'),\n",
        " ('they', 'PRP'),\n",
        " ('transform', 'VBP'),\n",
        " ('a', 'DT'),\n",
        " ('pretty', 'RB'),\n",
        " ('picture', 'NN'),\n",
        " ('into', 'IN'),\n",
        " ('a', 'DT'),\n",
        " ('moment.', 'NNP'),\n",
        " ('This', 'NNP'),\n",
        " ('Bacara', 'NNP'),\n",
        " ('Resort', 'NNP'),\n",
        " ('beauty', 'NN'),\n",
        " ('from', 'IN'),\n",
        " ('Michael', 'NNP'),\n",
        " ('Anna', 'NNP'),\n",
        " ('Costa', 'NNP'),\n",
        " ('came', 'VBD'),\n",
        " ('to', 'TO'),\n",
        " ('life', 'VB'),\n",
        " ('after', 'IN'),\n",
        " ('reading', 'NN'),\n",
        " ('the', 'DT'),\n",
        " ('Bride', 'NNP'),\n",
        " ('s', 'VBZ'),\n",
        " ('simply', 'RB'),\n",
        " ('sweet', 'JJ'),\n",
        " ('story', 'NN'),\n",
        " ('of', 'IN'),\n",
        " ('love', 'NN'),\n",
        " ('over', 'IN'),\n",
        " ('a', 'DT'),\n",
        " ('12', 'CD'),\n",
        " ('year', 'NN'),\n",
        " ('span.', 'NNP'),\n",
        " ('From', 'NNP'),\n",
        " ('high', 'JJ'),\n",
        " ('school', 'NN'),\n",
        " ('sweethearts', 'NNS'),\n",
        " ('to', 'TO'),\n",
        " ('college', 'VB'),\n",
        " ('a', 'DT'),\n",
        " ('move', 'NN'),\n",
        " ('to', 'TO'),\n",
        " ('the', 'DT'),\n",
        " ('caribbean', 'JJ'),\n",
        " ('a', 'DT'),\n",
        " ('proposal', 'NN'),\n",
        " ('and', 'CC'),\n",
        " ('planning', 'VBG'),\n",
        " ('a', 'DT'),\n",
        " ('wedding', 'NN'),\n",
        " ('with', 'IN'),\n",
        " ('the', 'DT'),\n",
        " ('help', 'NN'),\n",
        " ('of', 'IN'),\n",
        " ('Bob', 'NNP'),\n",
        " ('Gail', 'NNP'),\n",
        " ('Special', 'NNP'),\n",
        " ('Events', 'NNP'),\n",
        " ('you', 'PRP'),\n",
        " ('can', 'MD'),\n",
        " ('feel', 'VB'),\n",
        " ('the', 'DT'),\n",
        " ('love', 'NN'),\n",
        " ('pouring', 'VBG'),\n",
        " ('from', 'IN'),\n",
        " ('this', 'DT'),\n",
        " ('gallery', 'NN')]"
       ]
      }
     ],
     "prompt_number": 478
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = 'I wanted the look to be elegant classic and timeless but also contemporary and fresh'\n",
      "\n",
      "grammar = nltk.CFG.fromstring(\"\"\"\n",
      "S-> NP V NP\n",
      "NP -> NP\n",
      "V ->\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'CFG'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-418-8a4646f37ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I wanted the look to be elegant classic and timeless but also contemporary and fresh'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m grammar = nltk.CFG.fromstring(\"\"\"\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mNP\u001b[0m \u001b[0mV\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNP\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'CFG'"
       ]
      }
     ],
     "prompt_number": 418
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}